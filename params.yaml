# params.yaml

#model
AUGMENTATION: True
include_top: False  # Don't include the top fully connected layers
weights: "imagenet"  # Use pre-trained ImageNet weights
input_shape: [224, 224, 1]  # Grayscale input shape
 
#training
optimizer: "Adam"
learning_rate: 0.001  # Fine-tuning learning rate
loss: "binary_crossentropy"
metrics: ["accuracy"]
freeze_layers: 10   # Unfreeze first 10 layers for fine-tuning
classes: 2  # Number of classes in the classification task
batch_size: 32
epochs: 10

